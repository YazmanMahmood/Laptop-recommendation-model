{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "FqdWEa71hBAD",
        "outputId": "52edb8ae-231a-4a5f-fc0e-e6d0270abf52"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-60b3387909f6>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingArguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import json\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "from datasets import Dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# Filepaths\n",
        "DATASET_FILE = \"/content/temp_cleaned_laptops.csv\"\n",
        "JSON_FILE = \"/content/merged_file.json\"\n",
        "MODEL_DIR = \"./laptop_recommendation_model\"\n",
        "\n",
        "# Ensure model directory exists\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "def preprocess_data(dataset_file, json_file):\n",
        "    \"\"\"\n",
        "    Preprocess dataset and intents for model training\n",
        "\n",
        "    Args:\n",
        "        dataset_file (str): Path to laptop dataset CSV\n",
        "        json_file (str): Path to intents JSON file\n",
        "\n",
        "    Returns:\n",
        "        tuple: Processed training dataframe, intent mappings, and original laptop dataframe\n",
        "    \"\"\"\n",
        "    print(\"\\n--- Preprocessing Data ---\")\n",
        "\n",
        "    # Load laptop dataset\n",
        "    df = pd.read_csv(dataset_file)\n",
        "    print(f\"Dataset loaded with {len(df)} rows.\")\n",
        "\n",
        "    # Load intents\n",
        "    with open(json_file, 'r') as file:\n",
        "        intents = json.load(file)[\"intents\"]\n",
        "    print(f\"Loaded intents with {len(intents)} tags.\")\n",
        "\n",
        "    # Create training data\n",
        "    training_data = []\n",
        "    intent_to_label = {}\n",
        "    label_to_intent = {}\n",
        "\n",
        "    # Map intents to numeric labels\n",
        "    for idx, intent in enumerate(intents):\n",
        "        intent_to_label[intent[\"tag\"]] = idx\n",
        "        label_to_intent[idx] = intent[\"tag\"]\n",
        "\n",
        "        # Add intent patterns\n",
        "        for pattern in intent[\"patterns\"]:\n",
        "            training_data.append({\"text\": pattern, \"label\": idx})\n",
        "\n",
        "    # Add laptop category and price hints as training data\n",
        "    for _, row in df.iterrows():\n",
        "        category = row[\"Category\"]\n",
        "        price = row[\"Price\"]\n",
        "        training_data.append({\n",
        "            \"text\": f\"{category} laptop recommendation under ${price}\",\n",
        "            \"label\": intent_to_label.get(\"recommendation\", 0)\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(training_data), intent_to_label, label_to_intent, df\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    \"\"\"\n",
        "    Compute evaluation metrics for the model\n",
        "\n",
        "    Args:\n",
        "        pred (EvalPrediction): Predictions and labels\n",
        "\n",
        "    Returns:\n",
        "        dict: Computed metrics\n",
        "    \"\"\"\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')\n",
        "    accuracy = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }\n",
        "\n",
        "def train_intent_model(training_df, num_labels):\n",
        "    \"\"\"\n",
        "    Train BERT model for intent classification\n",
        "\n",
        "    Args:\n",
        "        training_df (pd.DataFrame): Training data\n",
        "        num_labels (int): Number of intent labels\n",
        "\n",
        "    Returns:\n",
        "        tuple: Trained model, tokenizer, and trainer\n",
        "    \"\"\"\n",
        "    # Initialize tokenizer\n",
        "    tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "    def tokenize_function(examples):\n",
        "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "    # Prepare dataset\n",
        "    dataset = Dataset.from_pandas(training_df)\n",
        "    dataset = dataset.map(tokenize_function, batched=True)\n",
        "    dataset = dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "    # Set format for training\n",
        "    dataset[\"train\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "    dataset[\"test\"].set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "\n",
        "    # Initialize model\n",
        "    model = BertForSequenceClassification.from_pretrained(\n",
        "        \"bert-base-uncased\",\n",
        "        num_labels=num_labels\n",
        "    )\n",
        "\n",
        "    # Training arguments\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=MODEL_DIR,\n",
        "        num_train_epochs=5,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        warmup_steps=500,\n",
        "        weight_decay=0.01,\n",
        "        logging_dir=f\"{MODEL_DIR}/logs\",\n",
        "        logging_steps=10,\n",
        "        evaluation_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        load_best_model_at_end=True,\n",
        "        metric_for_best_model=\"f1\"\n",
        "    )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=dataset[\"train\"],\n",
        "        eval_dataset=dataset[\"test\"],\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    trainer.train()\n",
        "\n",
        "    # Save model and tokenizer\n",
        "    trainer.save_model(MODEL_DIR)\n",
        "    tokenizer.save_pretrained(MODEL_DIR)\n",
        "\n",
        "    return model, tokenizer, trainer\n",
        "\n",
        "def recommend_laptop(prompt, model, tokenizer, intent_to_label, df):\n",
        "    \"\"\"\n",
        "    Generate laptop recommendation based on user prompt\n",
        "\n",
        "    Args:\n",
        "        prompt (str): User query\n",
        "        model (BertForSequenceClassification): Trained intent classification model\n",
        "        tokenizer (BertTokenizer): Tokenizer used for encoding\n",
        "        intent_to_label (dict): Mapping of intents to numeric labels\n",
        "        df (pd.DataFrame): Laptop dataset\n",
        "\n",
        "    Returns:\n",
        "        str: Recommended laptop\n",
        "    \"\"\"\n",
        "    # Encode input\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Predict intent\n",
        "    with torch.no_grad():\n",
        "        intent_logits = model(**inputs).logits\n",
        "        intent_idx = torch.argmax(intent_logits).item()\n",
        "        intent = list(intent_to_label.keys())[intent_idx]\n",
        "\n",
        "    # Extract budget if mentioned\n",
        "    budget = None\n",
        "    if \"under $\" in prompt:\n",
        "        try:\n",
        "            budget = int(prompt.split(\"under $\")[-1].split()[0])\n",
        "        except (ValueError, IndexError):\n",
        "            pass\n",
        "\n",
        "    # Filter recommendations\n",
        "    recommendations = df[\n",
        "        (df[\"Category\"].str.contains(intent.split(\"_\")[0], case=False)) &\n",
        "        (df[\"Price\"] <= budget) if budget else True\n",
        "    ]\n",
        "\n",
        "    return recommendations.iloc[0][\"Product\"] if not recommendations.empty else \"No matching laptops found.\"\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main execution function for laptop recommendation system\n",
        "    \"\"\"\n",
        "    # Preprocess data\n",
        "    training_df, intent_to_label, label_to_intent, df = preprocess_data(\n",
        "        DATASET_FILE, JSON_FILE\n",
        "    )\n",
        "\n",
        "    # Train model\n",
        "    model, tokenizer, trainer = train_intent_model(\n",
        "        training_df,\n",
        "        len(intent_to_label)\n",
        "    )\n",
        "\n",
        "    # Example recommendations\n",
        "    test_prompts = [\n",
        "        \"Recommend a gaming laptop under $1000\",\n",
        "        \"Professional laptop for creative work\",\n",
        "        \"Affordable laptop for students\"\n",
        "    ]\n",
        "\n",
        "    print(\"\\n--- Laptop Recommendations ---\")\n",
        "    for prompt in test_prompts:\n",
        "        recommendation = recommend_laptop(\n",
        "            prompt, model, tokenizer, intent_to_label, df\n",
        "        )\n",
        "        print(f\"Prompt: {prompt}\")\n",
        "        print(f\"Recommendation: {recommendation}\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Corrected commands for installing dependencies and downloading the spaCy model\n",
        "!pip install nltk spacy torch transformers sentence-transformers pandas numpy scikit-learn optuna tqdm\n",
        "!python -m spacy download en_core_web_sm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xhNImKuhDY1",
        "outputId": "9af93d21-52f3-4354-f1ae-5f7459f3445c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.13.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (1.14.0)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.10/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (1.3.6)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.13.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.6)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.20.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.2)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import logging\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback,\n",
        "    AutoConfig\n",
        ")\n",
        "from torch.utils.data import Dataset as TorchDataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "from typing import List, Tuple, Dict, Any, Optional, Union\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from dataclasses import dataclass\n",
        "from torch import nn\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.tokenize import word_tokenize\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import spacy\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import optuna\n",
        "\n",
        "# Set up paths for Colab\n",
        "DATASET_FILE = \"/content/temp_cleaned_laptops.csv\"\n",
        "JSON_FILE = \"/content/merged_file.json\"\n",
        "MODEL_DIR = \"/content/laptop_recommendation_model\"\n",
        "LOG_DIR = \"/content/logs\"\n",
        "\n",
        "# Create necessary directories\n",
        "for directory in [os.path.dirname(DATASET_FILE), MODEL_DIR, LOG_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Install required packages and download resources\n",
        "def setup_environment():\n",
        "    try:\n",
        "        # Install required packages\n",
        "        os.system('pip install -q transformers nltk spacy pandas scikit-learn sentence-transformers torch')\n",
        "\n",
        "        # Download NLTK resources\n",
        "        nltk.download('punkt')\n",
        "        nltk.download('wordnet')\n",
        "        nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "        # Download spaCy model\n",
        "        os.system('python -m spacy download en_core_web_sm')\n",
        "\n",
        "        print(\"Environment setup completed successfully!\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error setting up environment: {e}\")\n",
        "\n",
        "# Set up logging with proper error handling\n",
        "try:\n",
        "    logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "        handlers=[\n",
        "            logging.FileHandler(os.path.join(LOG_DIR, \"chatbot.log\")),\n",
        "            logging.StreamHandler()\n",
        "        ]\n",
        "    )\n",
        "except Exception as e:\n",
        "    print(f\"Error setting up logging: {e}\")\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# Suppress warnings and logging\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "# Configuration optimized for Colab\n",
        "CONFIG = {\n",
        "    'max_length': 512,\n",
        "    'batch_size': 16,  # Increased for Colab's GPU\n",
        "    'num_epochs': 5,   # Increased for better training\n",
        "    'warmup_ratio': 0.1,\n",
        "    'weight_decay': 0.01,\n",
        "    'learning_rate': 2e-5,\n",
        "    'dropout': 0.1,\n",
        "    'focal_loss_alpha': 0.25,\n",
        "    'focal_loss_gamma': 2.0\n",
        "}\n",
        "\n",
        "def setup_nltk():\n",
        "    \"\"\"Download required NLTK resources\"\"\"\n",
        "    resources = ['wordnet', 'averaged_perceptron_tagger', 'omw-1.4']\n",
        "    for resource in resources:\n",
        "        try:\n",
        "            nltk.download(resource, quiet=True)\n",
        "        except Exception as e:\n",
        "            print(f\"Error downloading NLTK resource {resource}: {e}\")\n",
        "\n",
        "# Call setup at import time\n",
        "setup_nltk()\n",
        "\n",
        "# Try loading spaCy model\n",
        "try:\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "except:\n",
        "    os.system('python -m spacy download en_core_web_sm')\n",
        "    nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "@dataclass\n",
        "class LaptopSpecs:\n",
        "    ram: Optional[int] = None\n",
        "    gpu: Optional[str] = None\n",
        "    storage: Optional[str] = None\n",
        "    refresh_rate: Optional[int] = None\n",
        "    processor: Optional[str] = None\n",
        "    screen_size: Optional[float] = None\n",
        "    battery_life: Optional[int] = None\n",
        "    weight: Optional[float] = None\n",
        "\n",
        "def extract_specs(features_str: str) -> LaptopSpecs:\n",
        "    \"\"\"Enhanced specification extraction with more features\"\"\"\n",
        "    specs = LaptopSpecs()\n",
        "\n",
        "    # Enhanced RAM extraction\n",
        "    ram_match = re.search(r'(\\d+)\\s*GB\\s*(?:DDR\\d)?\\s*RAM', features_str, re.IGNORECASE)\n",
        "    if ram_match:\n",
        "        specs.ram = int(ram_match.group(1))\n",
        "\n",
        "    # Enhanced GPU extraction with more patterns\n",
        "    gpu_patterns = [\n",
        "        r'(NVIDIA|AMD)\\s+(RTX|GTX|Radeon)\\s*\\d*\\s*\\w*\\s*(?:Ti|Super)?',\n",
        "        r'Intel\\s+(?:UHD|Iris)\\s+Graphics\\s+\\w*'\n",
        "    ]\n",
        "    for pattern in gpu_patterns:\n",
        "        gpu_match = re.search(pattern, features_str, re.IGNORECASE)\n",
        "        if gpu_match:\n",
        "            specs.gpu = gpu_match.group(0)\n",
        "            break\n",
        "\n",
        "    # Enhanced storage extraction\n",
        "    storage_matches = re.findall(r'(\\d+)\\s*(GB|TB)\\s*(SSD|HDD|NVMe|PCIe)', features_str, re.IGNORECASE)\n",
        "    if storage_matches:\n",
        "        storage_list = []\n",
        "        for size, unit, type_ in storage_matches:\n",
        "            size = int(size)\n",
        "            if unit.upper() == 'TB':\n",
        "                size *= 1000\n",
        "            storage_list.append(f\"{size}GB {type_.upper()}\")\n",
        "        specs.storage = ', '.join(storage_list)\n",
        "\n",
        "    # Enhanced refresh rate extraction\n",
        "    refresh_match = re.search(r'(\\d+)\\s*Hz', features_str, re.IGNORECASE)\n",
        "    if refresh_match:\n",
        "        specs.refresh_rate = int(refresh_match.group(1))\n",
        "\n",
        "    # New: Processor extraction\n",
        "    processor_match = re.search(r'(Intel|AMD)\\s+\\w+\\s+\\w+(?:-\\w+)?', features_str)\n",
        "    if processor_match:\n",
        "        specs.processor = processor_match.group(0)\n",
        "\n",
        "    # New: Screen size extraction\n",
        "    screen_match = re.search(r'(\\d+\\.?\\d?)\"', features_str)\n",
        "    if screen_match:\n",
        "        specs.screen_size = float(screen_match.group(1))\n",
        "\n",
        "    # New: Battery life extraction\n",
        "    battery_match = re.search(r'(\\d+)\\s*(?:hr|hour|hrs)', features_str, re.IGNORECASE)\n",
        "    if battery_match:\n",
        "        specs.battery_life = int(battery_match.group(1))\n",
        "\n",
        "    # New: Weight extraction\n",
        "    weight_match = re.search(r'(\\d+\\.?\\d?)\\s*(?:kg|lbs)', features_str, re.IGNORECASE)\n",
        "    if weight_match:\n",
        "        weight = float(weight_match.group(1))\n",
        "        if 'lbs' in weight_match.group().lower():\n",
        "            weight *= 0.453592  # Convert to kg\n",
        "        specs.weight = weight\n",
        "\n",
        "    return specs\n",
        "\n",
        "class EnhancedScoring:\n",
        "    @staticmethod\n",
        "    def compute_laptop_score(row: pd.Series, requirements: str, required_specs: Dict) -> float:\n",
        "        \"\"\"Enhanced scoring system with weighted features and dynamic scoring\"\"\"\n",
        "        score = 0.0\n",
        "        features = extract_specs(row['Features'])\n",
        "\n",
        "        # Base score components\n",
        "        if 'Amazon Rating' in row and not pd.isna(row['Amazon Rating']):\n",
        "            score += float(row['Amazon Rating']) * 15  # Increased weight for ratings\n",
        "\n",
        "        # Price efficiency bonus\n",
        "        if 'Price' in row and not pd.isna(row['Price']):\n",
        "            price = float(row['Price'])\n",
        "            if price > 0:\n",
        "                price_efficiency = 1000 / price  # Normalized price efficiency\n",
        "                score += price_efficiency * 10\n",
        "\n",
        "        # Dynamic requirement scoring\n",
        "        req_lower = requirements.lower()\n",
        "\n",
        "        # Gaming laptop scoring with enhanced GPU considerations\n",
        "        if 'gaming' in req_lower:\n",
        "            if features.gpu:\n",
        "                gpu_upper = features.gpu.upper()\n",
        "                if 'RTX 30' in gpu_upper or 'RTX 40' in gpu_upper:\n",
        "                    score += 50\n",
        "                elif 'RTX 20' in gpu_upper:\n",
        "                    score += 40\n",
        "                elif 'RTX' in gpu_upper:\n",
        "                    score += 30\n",
        "                elif 'GTX' in gpu_upper:\n",
        "                    score += 20\n",
        "\n",
        "            if features.refresh_rate:\n",
        "                if features.refresh_rate >= 240:\n",
        "                    score += 25\n",
        "                elif features.refresh_rate >= 144:\n",
        "                    score += 20\n",
        "                elif features.refresh_rate >= 120:\n",
        "                    score += 15\n",
        "\n",
        "            if features.ram:\n",
        "                if features.ram >= 32:\n",
        "                    score += 30\n",
        "                elif features.ram >= 16:\n",
        "                    score += 20\n",
        "\n",
        "        # Professional/Business laptop scoring with enhanced criteria\n",
        "        if any(x in req_lower for x in ['business', 'professional', 'work']):\n",
        "            if features.weight and features.weight < 1.5:\n",
        "                score += 25\n",
        "            elif features.weight and features.weight < 2.0:\n",
        "                score += 15\n",
        "\n",
        "            if features.battery_life:\n",
        "                if features.battery_life >= 10:\n",
        "                    score += 25\n",
        "                elif features.battery_life >= 8:\n",
        "                    score += 15\n",
        "\n",
        "            if features.processor and ('Intel Core i7' in features.processor or 'Ryzen 7' in features.processor):\n",
        "                score += 20\n",
        "\n",
        "        # Student laptop scoring\n",
        "        if 'student' in req_lower:\n",
        "            if features.weight and features.weight < 2.0:\n",
        "                score += 20\n",
        "            if features.battery_life and features.battery_life >= 8:\n",
        "                score += 20\n",
        "            if 'Price' in row and row['Price'] < 800:\n",
        "                score += 25\n",
        "\n",
        "        # Content creation scoring\n",
        "        if any(x in req_lower for x in ['video editing', 'content creation', 'creative']):\n",
        "            if features.ram and features.ram >= 32:\n",
        "                score += 30\n",
        "            if features.gpu and 'RTX' in features.gpu.upper():\n",
        "                score += 25\n",
        "            if features.processor and any(x in features.processor for x in ['i7', 'i9', 'Ryzen 7', 'Ryzen 9']):\n",
        "                score += 25\n",
        "\n",
        "        # Required specs matching with weighted scoring\n",
        "        for spec, required_value in required_specs.items():\n",
        "            if spec == 'ram' and features.ram:\n",
        "                if features.ram >= required_value:\n",
        "                    score += 30\n",
        "                elif features.ram >= required_value * 0.75:\n",
        "                    score += 15\n",
        "            elif spec == 'gpu' and features.gpu:\n",
        "                if required_value.upper() in features.gpu.upper():\n",
        "                    score += 30\n",
        "            elif spec == 'storage' and features.storage:\n",
        "                storage_sizes = [int(s.split('GB')[0]) for s in features.storage.split(',')]\n",
        "                if any(size >= required_value for size in storage_sizes):\n",
        "                    score += 20\n",
        "\n",
        "        return score\n",
        "\n",
        "class CustomModel(nn.Module):\n",
        "    def __init__(self, base_model, num_labels: int):\n",
        "        super().__init__()\n",
        "        self.base_model = base_model\n",
        "        self.dropout = nn.Dropout(CONFIG['dropout'])\n",
        "        self.classifier = nn.Linear(base_model.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, **inputs):\n",
        "        outputs = self.base_model(**inputs)\n",
        "        pooled_output = outputs.last_hidden_state[:, 0]\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.classifier(pooled_output)\n",
        "        return logits\n",
        "\n",
        "    def gradient_checkpointing_enable(self, **kwargs):\n",
        "        # Pass all keyword arguments to the base model's method\n",
        "        self.base_model.gradient_checkpointing_enable(**kwargs)\n",
        "\n",
        "class LaptopDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "class EnhancedLaptopRecommendationModel:\n",
        "    def __init__(self, model_name: str = 'microsoft/deberta-v3-base'):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.label_encoder = LabelEncoder()\n",
        "        self.tokenizer = None\n",
        "        self.model = None\n",
        "        self.model_name = model_name\n",
        "        self.sentence_transformer = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "        self.intent_labels = {\n",
        "            'greeting': 0,\n",
        "            'gaming_laptop': 1,\n",
        "            'business_laptop': 2,\n",
        "            'programming_laptop': 3,\n",
        "            'compare_laptops': 4,\n",
        "            'high_performance_laptop': 5\n",
        "        }\n",
        "\n",
        "    def prepare_training_data(self) -> Tuple[List[str], List[int]]:\n",
        "        \"\"\"Prepare training data from JSON file\"\"\"\n",
        "        try:\n",
        "            with open(JSON_FILE, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            texts = []\n",
        "            labels = []\n",
        "\n",
        "            for intent in data['intents']:\n",
        "                tag = intent['tag']\n",
        "                if tag in self.intent_labels:\n",
        "                    label_id = self.intent_labels[tag]\n",
        "                    patterns = intent['patterns']\n",
        "                    texts.extend(patterns)\n",
        "                    labels.extend([label_id] * len(patterns))\n",
        "\n",
        "            if not texts or not labels:\n",
        "                raise ValueError(\"No training data found in JSON file\")\n",
        "\n",
        "            return texts, labels\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error preparing training data: {e}\")\n",
        "            raise\n",
        "\n",
        "    def train_model(self):\n",
        "        \"\"\"Train the laptop recommendation model\"\"\"\n",
        "        try:\n",
        "            logger.info(\"Starting model training...\")\n",
        "\n",
        "            # Load laptop dataset\n",
        "            laptop_df = pd.read_csv(DATASET_FILE)\n",
        "            if laptop_df.empty:\n",
        "                raise ValueError(\"Empty dataset loaded\")\n",
        "\n",
        "            logger.info(f\"Loaded dataset with {len(laptop_df)} rows\")\n",
        "\n",
        "            # Load and preprocess intent data\n",
        "            texts, labels = self.prepare_training_data()\n",
        "            logger.info(f\"Prepared {len(texts)} training examples with {len(set(labels))} unique intents\")\n",
        "\n",
        "            if len(texts) == 0 or len(labels) == 0:\n",
        "                raise ValueError(\"No training data available\")\n",
        "\n",
        "            # Split data into train and validation sets\n",
        "            train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "                texts, labels, test_size=0.2, random_state=42\n",
        "            )\n",
        "\n",
        "            # Initialize tokenizer and model\n",
        "            self.tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
        "                'bert-base-uncased',\n",
        "                num_labels=len(self.intent_labels)\n",
        "            )\n",
        "\n",
        "            # Move model to GPU if available\n",
        "            device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "            self.model.to(device)\n",
        "            logger.info(f\"Using device: {device}\")\n",
        "\n",
        "            # Create datasets\n",
        "            train_dataset = self.create_dataset(train_texts, train_labels)\n",
        "            val_dataset = self.create_dataset(val_texts, val_labels)\n",
        "\n",
        "            logger.info(f\"Train dataset size: {len(train_dataset)}\")\n",
        "            logger.info(f\"Validation dataset size: {len(val_dataset)}\")\n",
        "\n",
        "            # Set up training arguments\n",
        "            training_args = TrainingArguments(\n",
        "                output_dir=MODEL_DIR,\n",
        "                num_train_epochs=CONFIG['num_epochs'],\n",
        "                per_device_train_batch_size=CONFIG['batch_size'],\n",
        "                per_device_eval_batch_size=CONFIG['batch_size'],\n",
        "                warmup_ratio=CONFIG['warmup_ratio'],\n",
        "                weight_decay=CONFIG['weight_decay'],\n",
        "                learning_rate=CONFIG['learning_rate'],\n",
        "                evaluation_strategy=\"epoch\",\n",
        "                save_strategy=\"epoch\",\n",
        "                load_best_model_at_end=True,\n",
        "                push_to_hub=False,\n",
        "                fp16=torch.cuda.is_available(),\n",
        "                report_to=\"none\",\n",
        "                logging_dir=os.path.join(LOG_DIR, 'runs'),\n",
        "                logging_steps=10\n",
        "            )\n",
        "\n",
        "            # Initialize trainer\n",
        "            trainer = Trainer(\n",
        "                model=self.model,\n",
        "                args=training_args,\n",
        "                train_dataset=train_dataset,\n",
        "                eval_dataset=val_dataset\n",
        "            )\n",
        "\n",
        "            # Train model\n",
        "            logger.info(\"Training started...\")\n",
        "            trainer.train()\n",
        "            logger.info(\"Training completed!\")\n",
        "\n",
        "            # Save model and tokenizer\n",
        "            self.model.save_pretrained(MODEL_DIR)\n",
        "            self.tokenizer.save_pretrained(MODEL_DIR)\n",
        "            logger.info(f\"Model and tokenizer saved to {MODEL_DIR}\")\n",
        "\n",
        "            # Save intent labels mapping\n",
        "            with open(os.path.join(MODEL_DIR, 'intent_labels.json'), 'w') as f:\n",
        "                json.dump(self.intent_labels, f)\n",
        "\n",
        "            # Evaluate model\n",
        "            eval_results = trainer.evaluate()\n",
        "            logger.info(f\"Evaluation results: {eval_results}\")\n",
        "\n",
        "            return laptop_df\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error during model training: {e}\")\n",
        "            raise\n",
        "\n",
        "    def create_dataset(self, texts: List[str], labels: List[int]) -> Dataset:\n",
        "        \"\"\"Create a dataset from texts and labels\"\"\"\n",
        "        encodings = self.tokenizer(\n",
        "            texts,\n",
        "            truncation=True,\n",
        "            padding=True,\n",
        "            max_length=CONFIG['max_length'],\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        return LaptopDataset(\n",
        "            {k: v.numpy() for k, v in encodings.items()},\n",
        "            labels\n",
        "        )\n",
        "\n",
        "    def advanced_text_augmentation(self, texts: List[str], labels: List[str]) -> Tuple[List[str], List[str]]:\n",
        "        \"\"\"Advanced text augmentation with multiple techniques\"\"\"\n",
        "        augmented_data = []\n",
        "\n",
        "        for text, label in tqdm(zip(texts, labels), desc=\"Augmenting data\"):\n",
        "            try:\n",
        "                augmented_data.append((text, label))\n",
        "\n",
        "                # Simple word-based augmentation\n",
        "                words = text.split()\n",
        "\n",
        "                # Synonym replacement\n",
        "                for i, word in enumerate(words):\n",
        "                    synsets = wordnet.synsets(word)\n",
        "                    if synsets:\n",
        "                        synonyms = []\n",
        "                        for syn in synsets:\n",
        "                            for lemma in syn.lemmas():\n",
        "                                if lemma.name() != word:\n",
        "                                    synonyms.append(lemma.name())\n",
        "                        if synonyms:\n",
        "                            new_words = words.copy()\n",
        "                            new_words[i] = random.choice(synonyms)\n",
        "                            augmented_data.append((' '.join(new_words), label))\n",
        "\n",
        "                # Word dropout (randomly remove words)\n",
        "                if len(words) > 3:\n",
        "                    dropped = [w for w in words if random.random() > 0.1]\n",
        "                    if dropped:\n",
        "                        augmented_data.append((' '.join(dropped), label))\n",
        "\n",
        "                # Word order perturbation\n",
        "                if len(words) > 4:\n",
        "                    mid_words = words[1:-1]\n",
        "                    random.shuffle(mid_words)\n",
        "                    perturbed = [words[0]] + mid_words + [words[-1]]\n",
        "                    augmented_data.append((' '.join(perturbed), label))\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.warning(f\"Error augmenting text '{text}': {e}\")\n",
        "                continue\n",
        "\n",
        "        augmented_texts, augmented_labels = zip(*augmented_data)\n",
        "        return list(augmented_texts), list(augmented_labels)\n",
        "\n",
        "    def recommend_laptop(self, prompt: str, laptop_df: pd.DataFrame) -> str:\n",
        "        \"\"\"\n",
        "        Generate laptop recommendations based on user prompt\n",
        "        \"\"\"\n",
        "        if not self.model or not self.tokenizer:\n",
        "            raise ValueError(\"Model not trained or loaded.\")\n",
        "\n",
        "        try:\n",
        "            # Tokenize input\n",
        "            inputs = self.tokenizer(\n",
        "                prompt,\n",
        "                truncation=True,\n",
        "                padding=True,\n",
        "                max_length=CONFIG['max_length'],\n",
        "                return_tensors='pt'\n",
        "            )\n",
        "\n",
        "            # Move inputs to the same device as model\n",
        "            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
        "\n",
        "            # Get prediction\n",
        "            with torch.no_grad():\n",
        "                outputs = self.model(**inputs)\n",
        "                predicted_intent = torch.argmax(outputs.logits, dim=1).item()\n",
        "\n",
        "            intent_label = list(self.intent_labels.keys())[list(self.intent_labels.values()).index(predicted_intent)]\n",
        "\n",
        "            # Filter laptops based on intent and prompt\n",
        "            filtered_df = self.filter_laptops(laptop_df, intent_label, prompt)\n",
        "\n",
        "            if filtered_df.empty:\n",
        "                return \"Sorry, I couldn't find any laptops matching your criteria.\"\n",
        "\n",
        "            # Format recommendations\n",
        "            recommendations = []\n",
        "            for _, laptop in filtered_df.iterrows():\n",
        "                # Extract key features from the Features column\n",
        "                features = laptop['Features'].split(',') if isinstance(laptop['Features'], str) else []\n",
        "                features_formatted = \"\\n  • \".join(features)\n",
        "\n",
        "                rec = (\n",
        "                    f\"Product: {laptop['Product']}\\n\"\n",
        "                    f\"Category: {laptop['Category']}\\n\"\n",
        "                    f\"Price: ${laptop['Price']:,.2f}\\n\"\n",
        "                    f\"Features:\\n  • {features_formatted}\\n\"\n",
        "                )\n",
        "\n",
        "                # Add rating if available\n",
        "                if 'Amazon Rating' in laptop and pd.notnull(laptop['Amazon Rating']):\n",
        "                    rec += f\"Rating: {laptop['Amazon Rating']}/5.0\\n\"\n",
        "\n",
        "                recommendations.append(rec)\n",
        "\n",
        "            # Add a header based on the intent\n",
        "            headers = {\n",
        "                'gaming_laptop': \"🎮 Gaming Laptop Recommendations:\",\n",
        "                'business_laptop': \"💼 Professional Laptop Recommendations:\",\n",
        "                'programming_laptop': \"💻 Programming Laptop Recommendations:\",\n",
        "                'high_performance_laptop': \"⚡ High-Performance Laptop Recommendations:\"\n",
        "            }\n",
        "\n",
        "            header = headers.get(intent_label, \"🔍 Laptop Recommendations:\")\n",
        "            return f\"{header}\\n\\n\" + \"\\n---\\n\".join(recommendations)\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error generating recommendation: {e}\")\n",
        "            return f\"Sorry, an error occurred while generating recommendations: {str(e)}\"\n",
        "\n",
        "    def filter_laptops(self, df, intent, prompt):\n",
        "        \"\"\"Filter laptops based on intent and user prompt\"\"\"\n",
        "        filtered_df = df.copy()\n",
        "\n",
        "        # Convert price to numeric, removing currency symbols and commas\n",
        "        filtered_df['Price'] = pd.to_numeric(filtered_df['Price'].astype(str).str.replace('$', '').str.replace(',', ''), errors='coerce')\n",
        "\n",
        "        # Extract budget from prompt if present\n",
        "        budget_match = re.search(r'(?:under|below|less than|up to)?\\s*\\$?(\\d+(?:,\\d{3})*(?:\\.\\d{2})?)', prompt, re.IGNORECASE)\n",
        "        budget = float(budget_match.group(1).replace(',', '')) if budget_match else float('inf')\n",
        "\n",
        "        if budget != float('inf'):\n",
        "            filtered_df = filtered_df[filtered_df['Price'] <= budget]\n",
        "\n",
        "        # Video editing specific filters\n",
        "        if 'video' in intent.lower() or 'creative' in intent.lower():\n",
        "            filtered_df = filtered_df[\n",
        "                # Require dedicated GPU\n",
        "                (filtered_df['Features'].str.contains('RTX 30|RTX 40|RX 6800', case=False, regex=True)) &\n",
        "                # Prefer higher resolution displays\n",
        "                (filtered_df['Features'].str.contains('QHD|4K|2K|1440p', case=False, regex=True))\n",
        "            ]\n",
        "            # Extract RAM size and filter for 32GB or higher\n",
        "            filtered_df['RAM_Size'] = filtered_df['Features'].str.extract('(\\d+)\\s*GB').astype(float)\n",
        "            filtered_df = filtered_df[filtered_df['RAM_Size'] >= 32]\n",
        "\n",
        "        # High performance specific filters\n",
        "        elif 'high' in intent.lower() and 'performance' in intent.lower():\n",
        "            filtered_df = filtered_df[\n",
        "                # Premium price range\n",
        "                (filtered_df['Price'] >= 2000) &\n",
        "                # High-end processors\n",
        "                (filtered_df['Features'].str.contains('i9|Ryzen 9|M2 Max', case=False, regex=True)) &\n",
        "                # Dedicated GPU\n",
        "                (filtered_df['Features'].str.contains('RTX|RX', case=False, regex=True))\n",
        "            ]\n",
        "            # Extract RAM size and filter for 32GB or higher\n",
        "            filtered_df['RAM_Size'] = filtered_df['Features'].str.extract('(\\d+)\\s*GB').astype(float)\n",
        "            filtered_df = filtered_df[filtered_df['RAM_Size'] >= 32]\n",
        "\n",
        "        # Gaming specific filters\n",
        "        elif 'gaming' in intent.lower():\n",
        "            filtered_df = filtered_df[\n",
        "                filtered_df['Features'].str.contains('RTX 30|RTX 40|RX 6800', case=False, regex=True)\n",
        "            ]\n",
        "            # High refresh rate for gaming\n",
        "            filtered_df['Refresh_Rate'] = filtered_df['Features'].str.extract('(\\d+)\\s*Hz').astype(float)\n",
        "            filtered_df = filtered_df[filtered_df['Refresh_Rate'] >= 144]\n",
        "\n",
        "        # Student/Budget specific filters\n",
        "        elif 'student' in intent.lower() or 'budget' in intent.lower():\n",
        "            max_price = min(float(budget if budget != float('inf') else 1000), 1000)\n",
        "            filtered_df = filtered_df[filtered_df['Price'] <= max_price]\n",
        "\n",
        "        return filtered_df.sort_values(['Amazon Rating', 'Price'], ascending=[False, True]).head(5)\n",
        "\n",
        "    def score_laptop(self, row, prompt):\n",
        "        \"\"\"Score a laptop based on its features and the user's prompt\"\"\"\n",
        "        score = float(row['Amazon Rating']) * 10  # Base score from rating\n",
        "\n",
        "        features = str(row['Features']).lower()\n",
        "        prompt = prompt.lower()\n",
        "\n",
        "        # Extract key specifications\n",
        "        ram_match = re.search(r'(\\d+)\\s*GB', features)\n",
        "        ram_size = int(ram_match.group(1)) if ram_match else 8\n",
        "\n",
        "        refresh_match = re.search(r'(\\d+)\\s*Hz', features)\n",
        "        refresh_rate = int(refresh_match.group(1)) if refresh_match else 60\n",
        "\n",
        "        # GPU scoring\n",
        "        if 'RTX 40' in features:\n",
        "            score += 40  # Latest gen GPU\n",
        "        elif 'RTX 30' in features:\n",
        "            score += 30  # Previous gen GPU\n",
        "        elif 'RX 6800' in features:\n",
        "            score += 25  # AMD high-end GPU\n",
        "\n",
        "        # RAM scoring (exponential up to 64GB)\n",
        "        score += min(ram_size / 8, 8) * 5\n",
        "\n",
        "        # Display scoring\n",
        "        if 'QHD' in features or '2K' in features or '1440p' in features:\n",
        "            score += 15\n",
        "        elif '4K' in features:\n",
        "            score += 20\n",
        "\n",
        "        # Refresh rate scoring\n",
        "        score += min(refresh_rate / 60, 4) * 5\n",
        "\n",
        "        # CPU scoring\n",
        "        if 'i9' in features or 'ryzen 9' in features:\n",
        "            score += 25\n",
        "        elif 'i7' in features or 'ryzen 7' in features:\n",
        "            score += 20\n",
        "\n",
        "        # Storage scoring\n",
        "        if 'PCIe' in features or 'NVMe' in features:\n",
        "            score += 15\n",
        "        if '2 TB' in features:\n",
        "            score += 20\n",
        "        elif '1 TB' in features:\n",
        "            score += 15\n",
        "\n",
        "        # Task-specific scoring\n",
        "        if 'video' in prompt or 'creative' in prompt:\n",
        "            if ram_size >= 32:\n",
        "                score += 30\n",
        "            if 'RTX' in features:  # NVIDIA GPUs better for creative work\n",
        "                score += 20\n",
        "        elif 'gaming' in prompt:\n",
        "            if refresh_rate >= 144:\n",
        "                score += 25\n",
        "            if ram_size >= 16:\n",
        "                score += 15\n",
        "        elif 'high' in prompt and 'performance' in prompt:\n",
        "            if ram_size >= 32:\n",
        "                score += 30\n",
        "            if 'i9' in features or 'ryzen 9' in features:\n",
        "                score += 25\n",
        "\n",
        "        return score\n",
        "\n",
        "def main():\n",
        "    try:\n",
        "        # Initialize the recommendation model\n",
        "        recommendation_model = EnhancedLaptopRecommendationModel()\n",
        "\n",
        "        # Train the model\n",
        "        laptop_df = recommendation_model.train_model()\n",
        "\n",
        "        # Example recommendations\n",
        "        test_prompts = [\n",
        "            \"Recommend a gaming laptop under $1000\",\n",
        "            \"Professional laptop for creative work\",\n",
        "            \"Budget laptop for students\",\n",
        "            \"High-performance laptop for video editing\"\n",
        "        ]\n",
        "\n",
        "        for prompt in test_prompts:\n",
        "            recommendation = recommendation_model.recommend_laptop(prompt, laptop_df)\n",
        "            print(f\"\\nPrompt: {prompt}\")\n",
        "            print(f\"Recommendation:\\n{recommendation}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in main execution: {e}\")\n",
        "        raise\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "yS0-9qCmhFjc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f186a8-5084-4635-d5b1-09f7079de22d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'eval_loss': 1.726220726966858, 'eval_runtime': 0.0676, 'eval_samples_per_second': 295.924, 'eval_steps_per_second': 29.592, 'epoch': 1.0}\n",
            "{'loss': 1.7411, 'grad_norm': 6.103487014770508, 'learning_rate': 1.3636363636363637e-05, 'epoch': 2.0}\n",
            "{'eval_loss': 1.6626465320587158, 'eval_runtime': 0.0287, 'eval_samples_per_second': 696.092, 'eval_steps_per_second': 69.609, 'epoch': 2.0}\n",
            "{'eval_loss': 1.5907714366912842, 'eval_runtime': 0.0701, 'eval_samples_per_second': 285.394, 'eval_steps_per_second': 28.539, 'epoch': 3.0}\n",
            "{'loss': 1.5119, 'grad_norm': 6.250085353851318, 'learning_rate': 5.4545454545454545e-06, 'epoch': 4.0}\n",
            "{'eval_loss': 1.510888695716858, 'eval_runtime': 0.039, 'eval_samples_per_second': 512.557, 'eval_steps_per_second': 51.256, 'epoch': 4.0}\n",
            "{'eval_loss': 1.489843726158142, 'eval_runtime': 0.0344, 'eval_samples_per_second': 581.275, 'eval_steps_per_second': 58.127, 'epoch': 5.0}\n",
            "{'train_runtime': 163.1476, 'train_samples_per_second': 2.452, 'train_steps_per_second': 0.153, 'train_loss': 1.587996826171875, 'epoch': 5.0}\n",
            "{'eval_loss': 1.489843726158142, 'eval_runtime': 0.0324, 'eval_samples_per_second': 618.141, 'eval_steps_per_second': 61.814, 'epoch': 5.0}\n",
            "\n",
            "Prompt: Recommend a gaming laptop under $1000\n",
            "Recommendation:\n",
            "🎮 Gaming Laptop Recommendations:\n",
            "\n",
            "Product: Acer AMD 2022\n",
            "Category: Ultrabook Laptop PC\n",
            "Price: $799.99\n",
            "Features:\n",
            "  • 16-inch WUXGA (1920 x 1200) display with 165 Hz refresh rate\n",
            "  •  Intel Core i 7-13650 HX\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Acer AMD 2022\n",
            "Category: Ultrabook, Laptop, PC\n",
            "Price: $799.99\n",
            "Features:\n",
            "  • 16” WUXGA (1920 x 1200) display with 165 Hz refresh rate\n",
            "  •  Processor: Intel Core i 7-13650 HX\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: HP Intel 2024\n",
            "Category: Budget Laptop\n",
            "Price: $999.99\n",
            "Features:\n",
            "  • 16-inch WUXGA (1920 x 1200) display with 144 Hz refresh rate\n",
            "  •  Intel Core i 5-12450 H\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 64 GB DDR 4\n",
            "  •  Storage: 1 TB PCIe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: HP Intel 2024\n",
            "Category: Budget Laptop\n",
            "Price: $999.99\n",
            "Features:\n",
            "  • 16” WUXGA (1920 x 1200) display with 144 Hz refresh rate\n",
            "  •  Processor: Intel Core i 5-12450 H\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 64 GB DDR 4\n",
            "  •  Storage: 1 TB PCIe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: MSI Intel 2024\n",
            "Category: Ultrabook, Laptop, PC\n",
            "Price: $799.99\n",
            "Features:\n",
            "  • 15.6” Full HD (1920 x 1080) display with 165 Hz refresh rate\n",
            "  •  Processor: Intel Core i 5-12450 H\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 3050\n",
            "  •  RAM: 8 GB DDR 4\n",
            "  •  Storage: 256 GB SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 4.8/5.0\n",
            "\n",
            "\n",
            "Prompt: Professional laptop for creative work\n",
            "Recommendation:\n",
            "💻 Programming Laptop Recommendations:\n",
            "\n",
            "Product: Razer AMD 2023\n",
            "Category: Convertible Laptop PC\n",
            "Price: $599.99\n",
            "Features:\n",
            "  • 16-inch WUXGA (1920 x 1200) display with 120 Hz refresh rate\n",
            "  •  Intel Core i 5-12450 H\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 1 TB PCIe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Razer AMD 2023\n",
            "Category: Convertible, Laptop, PC\n",
            "Price: $599.99\n",
            "Features:\n",
            "  • 16” WUXGA (1920 x 1200) display with 120 Hz refresh rate\n",
            "  •  Processor: Intel Core i 5-12450 H\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 1 TB PCIe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: HP Intel 2024\n",
            "Category: Ultrabook, Laptop, PC\n",
            "Price: $599.99\n",
            "Features:\n",
            "  • 17.3” QHD (2560 x 1440) display with 60 Hz refresh rate\n",
            "  •  Processor: AMD Ryzen 7 7735 HS\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 3050\n",
            "  •  RAM: 64 GB DDR 4\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Acer AMD 2022\n",
            "Category: Ultrabook Laptop PC\n",
            "Price: $799.99\n",
            "Features:\n",
            "  • 16-inch WUXGA (1920 x 1200) display with 165 Hz refresh rate\n",
            "  •  Intel Core i 7-13650 HX\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Acer AMD 2022\n",
            "Category: Ultrabook, Laptop, PC\n",
            "Price: $799.99\n",
            "Features:\n",
            "  • 16” WUXGA (1920 x 1200) display with 165 Hz refresh rate\n",
            "  •  Processor: Intel Core i 7-13650 HX\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "\n",
            "Prompt: Budget laptop for students\n",
            "Recommendation:\n",
            "💻 Programming Laptop Recommendations:\n",
            "\n",
            "Product: Razer AMD 2023\n",
            "Category: Convertible Laptop PC\n",
            "Price: $599.99\n",
            "Features:\n",
            "  • 16-inch WUXGA (1920 x 1200) display with 120 Hz refresh rate\n",
            "  •  Intel Core i 5-12450 H\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 1 TB PCIe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Razer AMD 2023\n",
            "Category: Convertible, Laptop, PC\n",
            "Price: $599.99\n",
            "Features:\n",
            "  • 16” WUXGA (1920 x 1200) display with 120 Hz refresh rate\n",
            "  •  Processor: Intel Core i 5-12450 H\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 1 TB PCIe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: HP Intel 2024\n",
            "Category: Ultrabook, Laptop, PC\n",
            "Price: $599.99\n",
            "Features:\n",
            "  • 17.3” QHD (2560 x 1440) display with 60 Hz refresh rate\n",
            "  •  Processor: AMD Ryzen 7 7735 HS\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 3050\n",
            "  •  RAM: 64 GB DDR 4\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Acer AMD 2022\n",
            "Category: Ultrabook Laptop PC\n",
            "Price: $799.99\n",
            "Features:\n",
            "  • 16-inch WUXGA (1920 x 1200) display with 165 Hz refresh rate\n",
            "  •  Intel Core i 7-13650 HX\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Acer AMD 2022\n",
            "Category: Ultrabook, Laptop, PC\n",
            "Price: $799.99\n",
            "Features:\n",
            "  • 16” WUXGA (1920 x 1200) display with 165 Hz refresh rate\n",
            "  •  Processor: Intel Core i 7-13650 HX\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "\n",
            "Prompt: High-performance laptop for video editing\n",
            "Recommendation:\n",
            "💻 Programming Laptop Recommendations:\n",
            "\n",
            "Product: Razer AMD 2023\n",
            "Category: Convertible Laptop PC\n",
            "Price: $599.99\n",
            "Features:\n",
            "  • 16-inch WUXGA (1920 x 1200) display with 120 Hz refresh rate\n",
            "  •  Intel Core i 5-12450 H\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 1 TB PCIe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Razer AMD 2023\n",
            "Category: Convertible, Laptop, PC\n",
            "Price: $599.99\n",
            "Features:\n",
            "  • 16” WUXGA (1920 x 1200) display with 120 Hz refresh rate\n",
            "  •  Processor: Intel Core i 5-12450 H\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 1 TB PCIe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: HP Intel 2024\n",
            "Category: Ultrabook, Laptop, PC\n",
            "Price: $599.99\n",
            "Features:\n",
            "  • 17.3” QHD (2560 x 1440) display with 60 Hz refresh rate\n",
            "  •  Processor: AMD Ryzen 7 7735 HS\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 3050\n",
            "  •  RAM: 64 GB DDR 4\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Acer AMD 2022\n",
            "Category: Ultrabook Laptop PC\n",
            "Price: $799.99\n",
            "Features:\n",
            "  • 16-inch WUXGA (1920 x 1200) display with 165 Hz refresh rate\n",
            "  •  Intel Core i 7-13650 HX\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n",
            "---\n",
            "Product: Acer AMD 2022\n",
            "Category: Ultrabook, Laptop, PC\n",
            "Price: $799.99\n",
            "Features:\n",
            "  • 16” WUXGA (1920 x 1200) display with 165 Hz refresh rate\n",
            "  •  Processor: Intel Core i 7-13650 HX\n",
            "  •  Graphics Card: NVIDIA GeForce RTX 4060\n",
            "  •  RAM: 32 GB DDR 5\n",
            "  •  Storage: 512 GB NVMe SSD\n",
            "  •  Windows 11 Home\n",
            "  •  Wi-Fi 6 connectivity\n",
            "  •  Backlit keyboard\n",
            "  •  Slim and lightweight design\n",
            "Rating: 5.0/5.0\n",
            "\n"
          ]
        }
      ]
    }
  ]
}